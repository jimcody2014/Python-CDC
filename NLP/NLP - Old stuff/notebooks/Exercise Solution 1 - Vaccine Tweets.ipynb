{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Instructions\" data-toc-modified-id=\"Instructions-0\">Instructions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Get-data-from-kaggle.com\" data-toc-modified-id=\"Get-data-from-kaggle.com-0.1\">Get data from kaggle.com</a></span></li><li><span><a href=\"#Load-a-dataframe\" data-toc-modified-id=\"Load-a-dataframe-0.2\">Load a dataframe</a></span></li><li><span><a href=\"#Basic-pre-processing\" data-toc-modified-id=\"Basic-pre-processing-0.3\">Basic pre-processing</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "1. Load this data set from kaggle - kaggle datasets download -d gpreda/pfizer-vaccine-tweets\n",
    "2. Determine the shape of the dataframe\n",
    "3. Review the data types\n",
    "4. Drop the id column\n",
    "5. Check for null values\n",
    "6. Perform the following pre-processing on the 'text' column. \n",
    "    - (new column1) change all text to lowercase\n",
    "    - (new column2) use new column1 and remove contractions.  \n",
    "    - (new column3) use new column2 and string the data back together\n",
    "    - (new column4) use new column3 and tokenize into sentences\n",
    "    - (new column5) use new column3, again, and tokenize into words   \n",
    "    - (new column6) use new column5 and special characters\n",
    "    - (new column7) use new column6 and remove stop words\n",
    "    - (new column8) use new column7 and perform stemming\n",
    "    - (new column9) use new column8 and perform lemmanization\n",
    "    - add columns tweet length and tweet word count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data from kaggle.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "\n",
    "## Upload your kaggle json file (API Token)\n",
    "#files.upload()\n",
    "\n",
    "#!mkdir ~/.kaggle\n",
    "\n",
    "#!cp kaggle.json ~/.kaggle/\n",
    "\n",
    "#!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle datasets download -d gpreda/pfizer-vaccine-tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir data\n",
    "\n",
    "#!unzip zip file name -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls -l data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "\n",
    "# What other imports are required?\n",
    "#!pip install contractions\n",
    "#!pip install pyspellchecker\n",
    "\n",
    "import contractions\n",
    "import string\n",
    "#import re\n",
    "\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1340539111971516416</td>\n",
       "      <td>Rachel Roh</td>\n",
       "      <td>La Crescenta-Montrose, CA</td>\n",
       "      <td>Aggregator of Asian American news; scanning di...</td>\n",
       "      <td>2009-04-08 17:52:46</td>\n",
       "      <td>405</td>\n",
       "      <td>1692</td>\n",
       "      <td>3247</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-20 06:06:44</td>\n",
       "      <td>Same folks said daikon paste could treat a cyt...</td>\n",
       "      <td>['PfizerBioNTech']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1338158543359250433</td>\n",
       "      <td>Albert Fong</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Marketing dude, tech geek, heavy metal &amp; '80s ...</td>\n",
       "      <td>2009-09-21 15:27:30</td>\n",
       "      <td>834</td>\n",
       "      <td>666</td>\n",
       "      <td>178</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-13 16:27:13</td>\n",
       "      <td>While the world has been on the wrong side of ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1337858199140118533</td>\n",
       "      <td>eliüá±üáπüá™üá∫üëå</td>\n",
       "      <td>Your Bed</td>\n",
       "      <td>heil, hydra üñê‚ò∫</td>\n",
       "      <td>2020-06-25 23:30:28</td>\n",
       "      <td>10</td>\n",
       "      <td>88</td>\n",
       "      <td>155</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 20:33:45</td>\n",
       "      <td>#coronavirus #SputnikV #AstraZeneca #PfizerBio...</td>\n",
       "      <td>['coronavirus', 'SputnikV', 'AstraZeneca', 'Pf...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1337855739918835717</td>\n",
       "      <td>Charles Adler</td>\n",
       "      <td>Vancouver, BC - Canada</td>\n",
       "      <td>Hosting \"CharlesAdlerTonight\" Global News Radi...</td>\n",
       "      <td>2008-09-10 11:28:53</td>\n",
       "      <td>49165</td>\n",
       "      <td>3933</td>\n",
       "      <td>21853</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-12-12 20:23:59</td>\n",
       "      <td>Facts are immutable, Senator, even when you're...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>446</td>\n",
       "      <td>2129</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1337854064604966912</td>\n",
       "      <td>Citizen News Channel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Citizen News Channel bringing you an alternati...</td>\n",
       "      <td>2020-04-23 17:58:42</td>\n",
       "      <td>152</td>\n",
       "      <td>580</td>\n",
       "      <td>1473</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 20:17:19</td>\n",
       "      <td>Explain to me again why we need a vaccine @Bor...</td>\n",
       "      <td>['whereareallthesickpeople', 'PfizerBioNTech']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id             user_name              user_location  \\\n",
       "0  1340539111971516416            Rachel Roh  La Crescenta-Montrose, CA   \n",
       "1  1338158543359250433           Albert Fong          San Francisco, CA   \n",
       "2  1337858199140118533              eliüá±üáπüá™üá∫üëå                   Your Bed   \n",
       "3  1337855739918835717         Charles Adler     Vancouver, BC - Canada   \n",
       "4  1337854064604966912  Citizen News Channel                        NaN   \n",
       "\n",
       "                                    user_description         user_created  \\\n",
       "0  Aggregator of Asian American news; scanning di...  2009-04-08 17:52:46   \n",
       "1  Marketing dude, tech geek, heavy metal & '80s ...  2009-09-21 15:27:30   \n",
       "2                                     heil, hydra üñê‚ò∫  2020-06-25 23:30:28   \n",
       "3  Hosting \"CharlesAdlerTonight\" Global News Radi...  2008-09-10 11:28:53   \n",
       "4  Citizen News Channel bringing you an alternati...  2020-04-23 17:58:42   \n",
       "\n",
       "   user_followers  user_friends  user_favourites  user_verified  \\\n",
       "0             405          1692             3247          False   \n",
       "1             834           666              178          False   \n",
       "2              10            88              155          False   \n",
       "3           49165          3933            21853           True   \n",
       "4             152           580             1473          False   \n",
       "\n",
       "                  date                                               text  \\\n",
       "0  2020-12-20 06:06:44  Same folks said daikon paste could treat a cyt...   \n",
       "1  2020-12-13 16:27:13  While the world has been on the wrong side of ...   \n",
       "2  2020-12-12 20:33:45  #coronavirus #SputnikV #AstraZeneca #PfizerBio...   \n",
       "3  2020-12-12 20:23:59  Facts are immutable, Senator, even when you're...   \n",
       "4  2020-12-12 20:17:19  Explain to me again why we need a vaccine @Bor...   \n",
       "\n",
       "                                            hashtags               source  \\\n",
       "0                                 ['PfizerBioNTech']  Twitter for Android   \n",
       "1                                                NaN      Twitter Web App   \n",
       "2  ['coronavirus', 'SputnikV', 'AstraZeneca', 'Pf...  Twitter for Android   \n",
       "3                                                NaN      Twitter Web App   \n",
       "4     ['whereareallthesickpeople', 'PfizerBioNTech']   Twitter for iPhone   \n",
       "\n",
       "   retweets  favorites  is_retweet  \n",
       "0         0          0       False  \n",
       "1         1          1       False  \n",
       "2         0          0       False  \n",
       "3       446       2129       False  \n",
       "4         0          0       False  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfz = pd.read_csv('/Users/jimcody/Documents/2021Python/nlp/data/vaccination_tweets.csv')\n",
    "pfz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11003, 16)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11003 entries, 0 to 11002\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   id                11003 non-null  int64 \n",
      " 1   user_name         11003 non-null  object\n",
      " 2   user_location     8734 non-null   object\n",
      " 3   user_description  10323 non-null  object\n",
      " 4   user_created      11003 non-null  object\n",
      " 5   user_followers    11003 non-null  int64 \n",
      " 6   user_friends      11003 non-null  int64 \n",
      " 7   user_favourites   11003 non-null  int64 \n",
      " 8   user_verified     11003 non-null  bool  \n",
      " 9   date              11003 non-null  object\n",
      " 10  text              11003 non-null  object\n",
      " 11  hashtags          8426 non-null   object\n",
      " 12  source            11002 non-null  object\n",
      " 13  retweets          11003 non-null  int64 \n",
      " 14  favorites         11003 non-null  int64 \n",
      " 15  is_retweet        11003 non-null  bool  \n",
      "dtypes: bool(2), int64(6), object(8)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "pfz.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "drop_columns = {'id'}\n",
    "pfz = pfz.drop(columns = drop_columns)\n",
    "#pfz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change text to lowercase\n",
    "pfz['lower'] = pfz['text'].str.lower()\n",
    "#pfz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove contractions\n",
    "pfz['remove_ctr'] = pfz['lower'].apply(lambda x: [contractions.fix(word) for word in x.split()])\n",
    "#pfz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>lower</th>\n",
       "      <th>remove_ctr</th>\n",
       "      <th>review_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rachel Roh</td>\n",
       "      <td>La Crescenta-Montrose, CA</td>\n",
       "      <td>Aggregator of Asian American news; scanning di...</td>\n",
       "      <td>2009-04-08 17:52:46</td>\n",
       "      <td>405</td>\n",
       "      <td>1692</td>\n",
       "      <td>3247</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-20 06:06:44</td>\n",
       "      <td>Same folks said daikon paste could treat a cyt...</td>\n",
       "      <td>['PfizerBioNTech']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>same folks said daikon paste could treat a cyt...</td>\n",
       "      <td>[same, folks, said, daikon, paste, could, trea...</td>\n",
       "      <td>same folks said daikon paste could treat a cyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albert Fong</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Marketing dude, tech geek, heavy metal &amp; '80s ...</td>\n",
       "      <td>2009-09-21 15:27:30</td>\n",
       "      <td>834</td>\n",
       "      <td>666</td>\n",
       "      <td>178</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-13 16:27:13</td>\n",
       "      <td>While the world has been on the wrong side of ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>while the world has been on the wrong side of ...</td>\n",
       "      <td>[while, the, world, has, been, on, the, wrong,...</td>\n",
       "      <td>while the world has been on the wrong side of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eliüá±üáπüá™üá∫üëå</td>\n",
       "      <td>Your Bed</td>\n",
       "      <td>heil, hydra üñê‚ò∫</td>\n",
       "      <td>2020-06-25 23:30:28</td>\n",
       "      <td>10</td>\n",
       "      <td>88</td>\n",
       "      <td>155</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 20:33:45</td>\n",
       "      <td>#coronavirus #SputnikV #AstraZeneca #PfizerBio...</td>\n",
       "      <td>['coronavirus', 'SputnikV', 'AstraZeneca', 'Pf...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>#coronavirus #sputnikv #astrazeneca #pfizerbio...</td>\n",
       "      <td>[#coronavirus, #sputnikv, #astrazeneca, #pfize...</td>\n",
       "      <td>#coronavirus #sputnikv #astrazeneca #pfizerbio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charles Adler</td>\n",
       "      <td>Vancouver, BC - Canada</td>\n",
       "      <td>Hosting \"CharlesAdlerTonight\" Global News Radi...</td>\n",
       "      <td>2008-09-10 11:28:53</td>\n",
       "      <td>49165</td>\n",
       "      <td>3933</td>\n",
       "      <td>21853</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-12-12 20:23:59</td>\n",
       "      <td>Facts are immutable, Senator, even when you're...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>446</td>\n",
       "      <td>2129</td>\n",
       "      <td>False</td>\n",
       "      <td>facts are immutable, senator, even when you're...</td>\n",
       "      <td>[facts, are, immutable,, senator,, even, when,...</td>\n",
       "      <td>facts are immutable, senator, even when you ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Citizen News Channel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Citizen News Channel bringing you an alternati...</td>\n",
       "      <td>2020-04-23 17:58:42</td>\n",
       "      <td>152</td>\n",
       "      <td>580</td>\n",
       "      <td>1473</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 20:17:19</td>\n",
       "      <td>Explain to me again why we need a vaccine @Bor...</td>\n",
       "      <td>['whereareallthesickpeople', 'PfizerBioNTech']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>explain to me again why we need a vaccine @bor...</td>\n",
       "      <td>[explain, to, me, again, why, we, need, a, vac...</td>\n",
       "      <td>explain to me again why we need a vaccine @bor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user_name              user_location  \\\n",
       "0            Rachel Roh  La Crescenta-Montrose, CA   \n",
       "1           Albert Fong          San Francisco, CA   \n",
       "2              eliüá±üáπüá™üá∫üëå                   Your Bed   \n",
       "3         Charles Adler     Vancouver, BC - Canada   \n",
       "4  Citizen News Channel                        NaN   \n",
       "\n",
       "                                    user_description         user_created  \\\n",
       "0  Aggregator of Asian American news; scanning di...  2009-04-08 17:52:46   \n",
       "1  Marketing dude, tech geek, heavy metal & '80s ...  2009-09-21 15:27:30   \n",
       "2                                     heil, hydra üñê‚ò∫  2020-06-25 23:30:28   \n",
       "3  Hosting \"CharlesAdlerTonight\" Global News Radi...  2008-09-10 11:28:53   \n",
       "4  Citizen News Channel bringing you an alternati...  2020-04-23 17:58:42   \n",
       "\n",
       "   user_followers  user_friends  user_favourites  user_verified  \\\n",
       "0             405          1692             3247          False   \n",
       "1             834           666              178          False   \n",
       "2              10            88              155          False   \n",
       "3           49165          3933            21853           True   \n",
       "4             152           580             1473          False   \n",
       "\n",
       "                  date                                               text  \\\n",
       "0  2020-12-20 06:06:44  Same folks said daikon paste could treat a cyt...   \n",
       "1  2020-12-13 16:27:13  While the world has been on the wrong side of ...   \n",
       "2  2020-12-12 20:33:45  #coronavirus #SputnikV #AstraZeneca #PfizerBio...   \n",
       "3  2020-12-12 20:23:59  Facts are immutable, Senator, even when you're...   \n",
       "4  2020-12-12 20:17:19  Explain to me again why we need a vaccine @Bor...   \n",
       "\n",
       "                                            hashtags               source  \\\n",
       "0                                 ['PfizerBioNTech']  Twitter for Android   \n",
       "1                                                NaN      Twitter Web App   \n",
       "2  ['coronavirus', 'SputnikV', 'AstraZeneca', 'Pf...  Twitter for Android   \n",
       "3                                                NaN      Twitter Web App   \n",
       "4     ['whereareallthesickpeople', 'PfizerBioNTech']   Twitter for iPhone   \n",
       "\n",
       "   retweets  favorites  is_retweet  \\\n",
       "0         0          0       False   \n",
       "1         1          1       False   \n",
       "2         0          0       False   \n",
       "3       446       2129       False   \n",
       "4         0          0       False   \n",
       "\n",
       "                                               lower  \\\n",
       "0  same folks said daikon paste could treat a cyt...   \n",
       "1  while the world has been on the wrong side of ...   \n",
       "2  #coronavirus #sputnikv #astrazeneca #pfizerbio...   \n",
       "3  facts are immutable, senator, even when you're...   \n",
       "4  explain to me again why we need a vaccine @bor...   \n",
       "\n",
       "                                          remove_ctr  \\\n",
       "0  [same, folks, said, daikon, paste, could, trea...   \n",
       "1  [while, the, world, has, been, on, the, wrong,...   \n",
       "2  [#coronavirus, #sputnikv, #astrazeneca, #pfize...   \n",
       "3  [facts, are, immutable,, senator,, even, when,...   \n",
       "4  [explain, to, me, again, why, we, need, a, vac...   \n",
       "\n",
       "                                          review_new  \n",
       "0  same folks said daikon paste could treat a cyt...  \n",
       "1  while the world has been on the wrong side of ...  \n",
       "2  #coronavirus #sputnikv #astrazeneca #pfizerbio...  \n",
       "3  facts are immutable, senator, even when you ar...  \n",
       "4  explain to me again why we need a vaccine @bor...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change no_contract back to a string\n",
    "pfz[\"review_new\"] = [' '.join(map(str, l)) for l in pfz['remove_ctr']]\n",
    "pfz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenized sentences\n",
    "pfz['tokenized_sent'] = pfz['review_new'].apply(sent_tokenize)\n",
    "#pfz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenized words\n",
    "pfz['tokenized_word'] = pfz['review_new'].apply(word_tokenize)\n",
    "#pfz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(string.punctuation)  # String module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special characters  This uses the string module\n",
    "punc = string.punctuation\n",
    "pfz['no_punc'] = pfz['tokenized_word'].apply(lambda x: [word for word in x if word not in punc])\n",
    "#pfz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'down', 'the', 've', 'these', 'by', 'was', 'up', \"hadn't\", 'shan', 'wouldn', 'needn', \"should've\", 'ours', 'himself', 'shouldn', 'what', 'and', 'have', 'than', \"haven't\", \"you've\", 'which', 'when', \"doesn't\", 'is', 'his', 'herself', 'your', 'those', 'themselves', 'won', \"isn't\", \"you'll\", 'i', 'it', 'while', \"wasn't\", 'having', 'she', 'didn', 't', 'to', 'isn', 'them', 'both', 'but', 'will', 'too', 'some', 'couldn', 's', 'haven', 'at', 'don', 'weren', \"weren't\", 'her', 'you', 'few', 'do', 'such', 'all', \"aren't\", 'only', 'against', 'or', 'myself', 'ain', 'they', 'hasn', 'my', 'are', 'out', 'over', 'of', 'between', 'he', 'yours', 'not', 'as', 'their', \"won't\", 'did', 'so', 'about', 'an', 'most', 'any', \"you're\", 'y', 'after', \"mightn't\", 'on', \"shouldn't\", \"shan't\", 'with', 'm', 'him', 'am', 'in', \"needn't\", 'because', 'until', 'yourselves', 'mightn', 'further', 'there', 'into', 'before', 'whom', \"she's\", 'its', 'itself', 'our', 'below', 'can', \"hasn't\", 'we', 'being', \"wouldn't\", 're', 'had', 'why', 'should', 'very', 'wasn', 'own', 'll', 'now', 'above', 'each', 'if', 'here', 'more', 'were', 'no', 'again', 'be', 'been', 'who', \"that'll\", 'me', 'a', \"don't\", 'how', 'off', 'mustn', 'for', 'other', 'under', 'once', 'through', 'where', 'hers', 'has', 'same', 'hadn', 'then', 'ma', \"it's\", 'during', 'd', \"didn't\", 'ourselves', 'theirs', 'doesn', 'that', 'this', 'from', 'just', \"mustn't\", 'does', 'yourself', 'o', \"couldn't\", 'doing', \"you'd\", 'aren', 'nor'}\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfz['no_stopwords'] = pfz['no_punc'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "#pfz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to fly to Europe.  There is a fly on the wall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfz['pos_tags'] = pfz['no_stopwords'].apply(nltk.tag.pos_tag)\n",
    "#pfz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfz['wordnet_pos'] = pfz['pos_tags'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n",
    "#pfz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>...</th>\n",
       "      <th>lower</th>\n",
       "      <th>remove_ctr</th>\n",
       "      <th>review_new</th>\n",
       "      <th>tokenized_sent</th>\n",
       "      <th>tokenized_word</th>\n",
       "      <th>no_punc</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>wordnet_pos</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rachel Roh</td>\n",
       "      <td>La Crescenta-Montrose, CA</td>\n",
       "      <td>Aggregator of Asian American news; scanning di...</td>\n",
       "      <td>2009-04-08 17:52:46</td>\n",
       "      <td>405</td>\n",
       "      <td>1692</td>\n",
       "      <td>3247</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-20 06:06:44</td>\n",
       "      <td>Same folks said daikon paste could treat a cyt...</td>\n",
       "      <td>...</td>\n",
       "      <td>same folks said daikon paste could treat a cyt...</td>\n",
       "      <td>[same, folks, said, daikon, paste, could, trea...</td>\n",
       "      <td>same folks said daikon paste could treat a cyt...</td>\n",
       "      <td>[same folks said daikon paste could treat a cy...</td>\n",
       "      <td>[same, folks, said, daikon, paste, could, trea...</td>\n",
       "      <td>[same, folks, said, daikon, paste, could, trea...</td>\n",
       "      <td>[folks, said, daikon, paste, could, treat, cyt...</td>\n",
       "      <td>[(folks, NNS), (said, VBD), (daikon, JJ), (pas...</td>\n",
       "      <td>[(folks, n), (said, v), (daikon, a), (paste, n...</td>\n",
       "      <td>[folk, say, daikon, paste, could, treat, cytok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albert Fong</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Marketing dude, tech geek, heavy metal &amp; '80s ...</td>\n",
       "      <td>2009-09-21 15:27:30</td>\n",
       "      <td>834</td>\n",
       "      <td>666</td>\n",
       "      <td>178</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-13 16:27:13</td>\n",
       "      <td>While the world has been on the wrong side of ...</td>\n",
       "      <td>...</td>\n",
       "      <td>while the world has been on the wrong side of ...</td>\n",
       "      <td>[while, the, world, has, been, on, the, wrong,...</td>\n",
       "      <td>while the world has been on the wrong side of ...</td>\n",
       "      <td>[while the world has been on the wrong side of...</td>\n",
       "      <td>[while, the, world, has, been, on, the, wrong,...</td>\n",
       "      <td>[while, the, world, has, been, on, the, wrong,...</td>\n",
       "      <td>[world, wrong, side, history, year, hopefully,...</td>\n",
       "      <td>[(world, NN), (wrong, JJ), (side, NN), (histor...</td>\n",
       "      <td>[(world, n), (wrong, a), (side, n), (history, ...</td>\n",
       "      <td>[world, wrong, side, history, year, hopefully,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eliüá±üáπüá™üá∫üëå</td>\n",
       "      <td>Your Bed</td>\n",
       "      <td>heil, hydra üñê‚ò∫</td>\n",
       "      <td>2020-06-25 23:30:28</td>\n",
       "      <td>10</td>\n",
       "      <td>88</td>\n",
       "      <td>155</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 20:33:45</td>\n",
       "      <td>#coronavirus #SputnikV #AstraZeneca #PfizerBio...</td>\n",
       "      <td>...</td>\n",
       "      <td>#coronavirus #sputnikv #astrazeneca #pfizerbio...</td>\n",
       "      <td>[#coronavirus, #sputnikv, #astrazeneca, #pfize...</td>\n",
       "      <td>#coronavirus #sputnikv #astrazeneca #pfizerbio...</td>\n",
       "      <td>[#coronavirus #sputnikv #astrazeneca #pfizerbi...</td>\n",
       "      <td>[#, coronavirus, #, sputnikv, #, astrazeneca, ...</td>\n",
       "      <td>[coronavirus, sputnikv, astrazeneca, pfizerbio...</td>\n",
       "      <td>[coronavirus, sputnikv, astrazeneca, pfizerbio...</td>\n",
       "      <td>[(coronavirus, NN), (sputnikv, NN), (astrazene...</td>\n",
       "      <td>[(coronavirus, n), (sputnikv, n), (astrazeneca...</td>\n",
       "      <td>[coronavirus, sputnikv, astrazeneca, pfizerbio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charles Adler</td>\n",
       "      <td>Vancouver, BC - Canada</td>\n",
       "      <td>Hosting \"CharlesAdlerTonight\" Global News Radi...</td>\n",
       "      <td>2008-09-10 11:28:53</td>\n",
       "      <td>49165</td>\n",
       "      <td>3933</td>\n",
       "      <td>21853</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-12-12 20:23:59</td>\n",
       "      <td>Facts are immutable, Senator, even when you're...</td>\n",
       "      <td>...</td>\n",
       "      <td>facts are immutable, senator, even when you're...</td>\n",
       "      <td>[facts, are, immutable,, senator,, even, when,...</td>\n",
       "      <td>facts are immutable, senator, even when you ar...</td>\n",
       "      <td>[facts are immutable, senator, even when you a...</td>\n",
       "      <td>[facts, are, immutable, ,, senator, ,, even, w...</td>\n",
       "      <td>[facts, are, immutable, senator, even, when, y...</td>\n",
       "      <td>[facts, immutable, senator, even, ethically, s...</td>\n",
       "      <td>[(facts, NNS), (immutable, JJ), (senator, NN),...</td>\n",
       "      <td>[(facts, n), (immutable, a), (senator, n), (ev...</td>\n",
       "      <td>[fact, immutable, senator, even, ethically, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Citizen News Channel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Citizen News Channel bringing you an alternati...</td>\n",
       "      <td>2020-04-23 17:58:42</td>\n",
       "      <td>152</td>\n",
       "      <td>580</td>\n",
       "      <td>1473</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 20:17:19</td>\n",
       "      <td>Explain to me again why we need a vaccine @Bor...</td>\n",
       "      <td>...</td>\n",
       "      <td>explain to me again why we need a vaccine @bor...</td>\n",
       "      <td>[explain, to, me, again, why, we, need, a, vac...</td>\n",
       "      <td>explain to me again why we need a vaccine @bor...</td>\n",
       "      <td>[explain to me again why we need a vaccine @bo...</td>\n",
       "      <td>[explain, to, me, again, why, we, need, a, vac...</td>\n",
       "      <td>[explain, to, me, again, why, we, need, a, vac...</td>\n",
       "      <td>[explain, need, vaccine, borisjohnson, matthan...</td>\n",
       "      <td>[(explain, RB), (need, JJ), (vaccine, NN), (bo...</td>\n",
       "      <td>[(explain, r), (need, a), (vaccine, n), (boris...</td>\n",
       "      <td>[explain, need, vaccine, borisjohnson, matthan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              user_name              user_location  \\\n",
       "0            Rachel Roh  La Crescenta-Montrose, CA   \n",
       "1           Albert Fong          San Francisco, CA   \n",
       "2              eliüá±üáπüá™üá∫üëå                   Your Bed   \n",
       "3         Charles Adler     Vancouver, BC - Canada   \n",
       "4  Citizen News Channel                        NaN   \n",
       "\n",
       "                                    user_description         user_created  \\\n",
       "0  Aggregator of Asian American news; scanning di...  2009-04-08 17:52:46   \n",
       "1  Marketing dude, tech geek, heavy metal & '80s ...  2009-09-21 15:27:30   \n",
       "2                                     heil, hydra üñê‚ò∫  2020-06-25 23:30:28   \n",
       "3  Hosting \"CharlesAdlerTonight\" Global News Radi...  2008-09-10 11:28:53   \n",
       "4  Citizen News Channel bringing you an alternati...  2020-04-23 17:58:42   \n",
       "\n",
       "   user_followers  user_friends  user_favourites  user_verified  \\\n",
       "0             405          1692             3247          False   \n",
       "1             834           666              178          False   \n",
       "2              10            88              155          False   \n",
       "3           49165          3933            21853           True   \n",
       "4             152           580             1473          False   \n",
       "\n",
       "                  date                                               text  \\\n",
       "0  2020-12-20 06:06:44  Same folks said daikon paste could treat a cyt...   \n",
       "1  2020-12-13 16:27:13  While the world has been on the wrong side of ...   \n",
       "2  2020-12-12 20:33:45  #coronavirus #SputnikV #AstraZeneca #PfizerBio...   \n",
       "3  2020-12-12 20:23:59  Facts are immutable, Senator, even when you're...   \n",
       "4  2020-12-12 20:17:19  Explain to me again why we need a vaccine @Bor...   \n",
       "\n",
       "   ...                                              lower  \\\n",
       "0  ...  same folks said daikon paste could treat a cyt...   \n",
       "1  ...  while the world has been on the wrong side of ...   \n",
       "2  ...  #coronavirus #sputnikv #astrazeneca #pfizerbio...   \n",
       "3  ...  facts are immutable, senator, even when you're...   \n",
       "4  ...  explain to me again why we need a vaccine @bor...   \n",
       "\n",
       "                                          remove_ctr  \\\n",
       "0  [same, folks, said, daikon, paste, could, trea...   \n",
       "1  [while, the, world, has, been, on, the, wrong,...   \n",
       "2  [#coronavirus, #sputnikv, #astrazeneca, #pfize...   \n",
       "3  [facts, are, immutable,, senator,, even, when,...   \n",
       "4  [explain, to, me, again, why, we, need, a, vac...   \n",
       "\n",
       "                                          review_new  \\\n",
       "0  same folks said daikon paste could treat a cyt...   \n",
       "1  while the world has been on the wrong side of ...   \n",
       "2  #coronavirus #sputnikv #astrazeneca #pfizerbio...   \n",
       "3  facts are immutable, senator, even when you ar...   \n",
       "4  explain to me again why we need a vaccine @bor...   \n",
       "\n",
       "                                      tokenized_sent  \\\n",
       "0  [same folks said daikon paste could treat a cy...   \n",
       "1  [while the world has been on the wrong side of...   \n",
       "2  [#coronavirus #sputnikv #astrazeneca #pfizerbi...   \n",
       "3  [facts are immutable, senator, even when you a...   \n",
       "4  [explain to me again why we need a vaccine @bo...   \n",
       "\n",
       "                                      tokenized_word  \\\n",
       "0  [same, folks, said, daikon, paste, could, trea...   \n",
       "1  [while, the, world, has, been, on, the, wrong,...   \n",
       "2  [#, coronavirus, #, sputnikv, #, astrazeneca, ...   \n",
       "3  [facts, are, immutable, ,, senator, ,, even, w...   \n",
       "4  [explain, to, me, again, why, we, need, a, vac...   \n",
       "\n",
       "                                             no_punc  \\\n",
       "0  [same, folks, said, daikon, paste, could, trea...   \n",
       "1  [while, the, world, has, been, on, the, wrong,...   \n",
       "2  [coronavirus, sputnikv, astrazeneca, pfizerbio...   \n",
       "3  [facts, are, immutable, senator, even, when, y...   \n",
       "4  [explain, to, me, again, why, we, need, a, vac...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  [folks, said, daikon, paste, could, treat, cyt...   \n",
       "1  [world, wrong, side, history, year, hopefully,...   \n",
       "2  [coronavirus, sputnikv, astrazeneca, pfizerbio...   \n",
       "3  [facts, immutable, senator, even, ethically, s...   \n",
       "4  [explain, need, vaccine, borisjohnson, matthan...   \n",
       "\n",
       "                                            pos_tags  \\\n",
       "0  [(folks, NNS), (said, VBD), (daikon, JJ), (pas...   \n",
       "1  [(world, NN), (wrong, JJ), (side, NN), (histor...   \n",
       "2  [(coronavirus, NN), (sputnikv, NN), (astrazene...   \n",
       "3  [(facts, NNS), (immutable, JJ), (senator, NN),...   \n",
       "4  [(explain, RB), (need, JJ), (vaccine, NN), (bo...   \n",
       "\n",
       "                                         wordnet_pos  \\\n",
       "0  [(folks, n), (said, v), (daikon, a), (paste, n...   \n",
       "1  [(world, n), (wrong, a), (side, n), (history, ...   \n",
       "2  [(coronavirus, n), (sputnikv, n), (astrazeneca...   \n",
       "3  [(facts, n), (immutable, a), (senator, n), (ev...   \n",
       "4  [(explain, r), (need, a), (vaccine, n), (boris...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  [folk, say, daikon, paste, could, treat, cytok...  \n",
       "1  [world, wrong, side, history, year, hopefully,...  \n",
       "2  [coronavirus, sputnikv, astrazeneca, pfizerbio...  \n",
       "3  [fact, immutable, senator, even, ethically, st...  \n",
       "4  [explain, need, vaccine, borisjohnson, matthan...  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "pfz['lemmatized'] = pfz['wordnet_pos'].apply(lambda x: [wnl.lemmatize(word, tag) for word, tag in x])\n",
    "pfz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfz['review_len'] = pfz['text'].astype(str).apply(len)\n",
    "pfz['word_count'] = pfz['text'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>...</th>\n",
       "      <th>review_new</th>\n",
       "      <th>tokenized_sent</th>\n",
       "      <th>tokenized_word</th>\n",
       "      <th>no_punc</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>wordnet_pos</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>review_len</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rachel Roh</td>\n",
       "      <td>La Crescenta-Montrose, CA</td>\n",
       "      <td>Aggregator of Asian American news; scanning di...</td>\n",
       "      <td>2009-04-08 17:52:46</td>\n",
       "      <td>405</td>\n",
       "      <td>1692</td>\n",
       "      <td>3247</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-20 06:06:44</td>\n",
       "      <td>Same folks said daikon paste could treat a cyt...</td>\n",
       "      <td>...</td>\n",
       "      <td>same folks said daikon paste could treat a cyt...</td>\n",
       "      <td>[same folks said daikon paste could treat a cy...</td>\n",
       "      <td>[same, folks, said, daikon, paste, could, trea...</td>\n",
       "      <td>[same, folks, said, daikon, paste, could, trea...</td>\n",
       "      <td>[folks, said, daikon, paste, could, treat, cyt...</td>\n",
       "      <td>[(folks, NNS), (said, VBD), (daikon, JJ), (pas...</td>\n",
       "      <td>[(folks, n), (said, v), (daikon, a), (paste, n...</td>\n",
       "      <td>[folk, say, daikon, paste, could, treat, cytok...</td>\n",
       "      <td>97</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albert Fong</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Marketing dude, tech geek, heavy metal &amp; '80s ...</td>\n",
       "      <td>2009-09-21 15:27:30</td>\n",
       "      <td>834</td>\n",
       "      <td>666</td>\n",
       "      <td>178</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-13 16:27:13</td>\n",
       "      <td>While the world has been on the wrong side of ...</td>\n",
       "      <td>...</td>\n",
       "      <td>while the world has been on the wrong side of ...</td>\n",
       "      <td>[while the world has been on the wrong side of...</td>\n",
       "      <td>[while, the, world, has, been, on, the, wrong,...</td>\n",
       "      <td>[while, the, world, has, been, on, the, wrong,...</td>\n",
       "      <td>[world, wrong, side, history, year, hopefully,...</td>\n",
       "      <td>[(world, NN), (wrong, JJ), (side, NN), (histor...</td>\n",
       "      <td>[(world, n), (wrong, a), (side, n), (history, ...</td>\n",
       "      <td>[world, wrong, side, history, year, hopefully,...</td>\n",
       "      <td>140</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eliüá±üáπüá™üá∫üëå</td>\n",
       "      <td>Your Bed</td>\n",
       "      <td>heil, hydra üñê‚ò∫</td>\n",
       "      <td>2020-06-25 23:30:28</td>\n",
       "      <td>10</td>\n",
       "      <td>88</td>\n",
       "      <td>155</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 20:33:45</td>\n",
       "      <td>#coronavirus #SputnikV #AstraZeneca #PfizerBio...</td>\n",
       "      <td>...</td>\n",
       "      <td>#coronavirus #sputnikv #astrazeneca #pfizerbio...</td>\n",
       "      <td>[#coronavirus #sputnikv #astrazeneca #pfizerbi...</td>\n",
       "      <td>[#, coronavirus, #, sputnikv, #, astrazeneca, ...</td>\n",
       "      <td>[coronavirus, sputnikv, astrazeneca, pfizerbio...</td>\n",
       "      <td>[coronavirus, sputnikv, astrazeneca, pfizerbio...</td>\n",
       "      <td>[(coronavirus, NN), (sputnikv, NN), (astrazene...</td>\n",
       "      <td>[(coronavirus, n), (sputnikv, n), (astrazeneca...</td>\n",
       "      <td>[coronavirus, sputnikv, astrazeneca, pfizerbio...</td>\n",
       "      <td>140</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charles Adler</td>\n",
       "      <td>Vancouver, BC - Canada</td>\n",
       "      <td>Hosting \"CharlesAdlerTonight\" Global News Radi...</td>\n",
       "      <td>2008-09-10 11:28:53</td>\n",
       "      <td>49165</td>\n",
       "      <td>3933</td>\n",
       "      <td>21853</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-12-12 20:23:59</td>\n",
       "      <td>Facts are immutable, Senator, even when you're...</td>\n",
       "      <td>...</td>\n",
       "      <td>facts are immutable, senator, even when you ar...</td>\n",
       "      <td>[facts are immutable, senator, even when you a...</td>\n",
       "      <td>[facts, are, immutable, ,, senator, ,, even, w...</td>\n",
       "      <td>[facts, are, immutable, senator, even, when, y...</td>\n",
       "      <td>[facts, immutable, senator, even, ethically, s...</td>\n",
       "      <td>[(facts, NNS), (immutable, JJ), (senator, NN),...</td>\n",
       "      <td>[(facts, n), (immutable, a), (senator, n), (ev...</td>\n",
       "      <td>[fact, immutable, senator, even, ethically, st...</td>\n",
       "      <td>140</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Citizen News Channel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Citizen News Channel bringing you an alternati...</td>\n",
       "      <td>2020-04-23 17:58:42</td>\n",
       "      <td>152</td>\n",
       "      <td>580</td>\n",
       "      <td>1473</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 20:17:19</td>\n",
       "      <td>Explain to me again why we need a vaccine @Bor...</td>\n",
       "      <td>...</td>\n",
       "      <td>explain to me again why we need a vaccine @bor...</td>\n",
       "      <td>[explain to me again why we need a vaccine @bo...</td>\n",
       "      <td>[explain, to, me, again, why, we, need, a, vac...</td>\n",
       "      <td>[explain, to, me, again, why, we, need, a, vac...</td>\n",
       "      <td>[explain, need, vaccine, borisjohnson, matthan...</td>\n",
       "      <td>[(explain, RB), (need, JJ), (vaccine, NN), (bo...</td>\n",
       "      <td>[(explain, r), (need, a), (vaccine, n), (boris...</td>\n",
       "      <td>[explain, need, vaccine, borisjohnson, matthan...</td>\n",
       "      <td>135</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              user_name              user_location  \\\n",
       "0            Rachel Roh  La Crescenta-Montrose, CA   \n",
       "1           Albert Fong          San Francisco, CA   \n",
       "2              eliüá±üáπüá™üá∫üëå                   Your Bed   \n",
       "3         Charles Adler     Vancouver, BC - Canada   \n",
       "4  Citizen News Channel                        NaN   \n",
       "\n",
       "                                    user_description         user_created  \\\n",
       "0  Aggregator of Asian American news; scanning di...  2009-04-08 17:52:46   \n",
       "1  Marketing dude, tech geek, heavy metal & '80s ...  2009-09-21 15:27:30   \n",
       "2                                     heil, hydra üñê‚ò∫  2020-06-25 23:30:28   \n",
       "3  Hosting \"CharlesAdlerTonight\" Global News Radi...  2008-09-10 11:28:53   \n",
       "4  Citizen News Channel bringing you an alternati...  2020-04-23 17:58:42   \n",
       "\n",
       "   user_followers  user_friends  user_favourites  user_verified  \\\n",
       "0             405          1692             3247          False   \n",
       "1             834           666              178          False   \n",
       "2              10            88              155          False   \n",
       "3           49165          3933            21853           True   \n",
       "4             152           580             1473          False   \n",
       "\n",
       "                  date                                               text  \\\n",
       "0  2020-12-20 06:06:44  Same folks said daikon paste could treat a cyt...   \n",
       "1  2020-12-13 16:27:13  While the world has been on the wrong side of ...   \n",
       "2  2020-12-12 20:33:45  #coronavirus #SputnikV #AstraZeneca #PfizerBio...   \n",
       "3  2020-12-12 20:23:59  Facts are immutable, Senator, even when you're...   \n",
       "4  2020-12-12 20:17:19  Explain to me again why we need a vaccine @Bor...   \n",
       "\n",
       "   ...                                         review_new  \\\n",
       "0  ...  same folks said daikon paste could treat a cyt...   \n",
       "1  ...  while the world has been on the wrong side of ...   \n",
       "2  ...  #coronavirus #sputnikv #astrazeneca #pfizerbio...   \n",
       "3  ...  facts are immutable, senator, even when you ar...   \n",
       "4  ...  explain to me again why we need a vaccine @bor...   \n",
       "\n",
       "                                      tokenized_sent  \\\n",
       "0  [same folks said daikon paste could treat a cy...   \n",
       "1  [while the world has been on the wrong side of...   \n",
       "2  [#coronavirus #sputnikv #astrazeneca #pfizerbi...   \n",
       "3  [facts are immutable, senator, even when you a...   \n",
       "4  [explain to me again why we need a vaccine @bo...   \n",
       "\n",
       "                                      tokenized_word  \\\n",
       "0  [same, folks, said, daikon, paste, could, trea...   \n",
       "1  [while, the, world, has, been, on, the, wrong,...   \n",
       "2  [#, coronavirus, #, sputnikv, #, astrazeneca, ...   \n",
       "3  [facts, are, immutable, ,, senator, ,, even, w...   \n",
       "4  [explain, to, me, again, why, we, need, a, vac...   \n",
       "\n",
       "                                             no_punc  \\\n",
       "0  [same, folks, said, daikon, paste, could, trea...   \n",
       "1  [while, the, world, has, been, on, the, wrong,...   \n",
       "2  [coronavirus, sputnikv, astrazeneca, pfizerbio...   \n",
       "3  [facts, are, immutable, senator, even, when, y...   \n",
       "4  [explain, to, me, again, why, we, need, a, vac...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  [folks, said, daikon, paste, could, treat, cyt...   \n",
       "1  [world, wrong, side, history, year, hopefully,...   \n",
       "2  [coronavirus, sputnikv, astrazeneca, pfizerbio...   \n",
       "3  [facts, immutable, senator, even, ethically, s...   \n",
       "4  [explain, need, vaccine, borisjohnson, matthan...   \n",
       "\n",
       "                                            pos_tags  \\\n",
       "0  [(folks, NNS), (said, VBD), (daikon, JJ), (pas...   \n",
       "1  [(world, NN), (wrong, JJ), (side, NN), (histor...   \n",
       "2  [(coronavirus, NN), (sputnikv, NN), (astrazene...   \n",
       "3  [(facts, NNS), (immutable, JJ), (senator, NN),...   \n",
       "4  [(explain, RB), (need, JJ), (vaccine, NN), (bo...   \n",
       "\n",
       "                                         wordnet_pos  \\\n",
       "0  [(folks, n), (said, v), (daikon, a), (paste, n...   \n",
       "1  [(world, n), (wrong, a), (side, n), (history, ...   \n",
       "2  [(coronavirus, n), (sputnikv, n), (astrazeneca...   \n",
       "3  [(facts, n), (immutable, a), (senator, n), (ev...   \n",
       "4  [(explain, r), (need, a), (vaccine, n), (boris...   \n",
       "\n",
       "                                          lemmatized review_len word_count  \n",
       "0  [folk, say, daikon, paste, could, treat, cytok...         97         12  \n",
       "1  [world, wrong, side, history, year, hopefully,...        140         21  \n",
       "2  [coronavirus, sputnikv, astrazeneca, pfizerbio...        140         15  \n",
       "3  [fact, immutable, senator, even, ethically, st...        140         20  \n",
       "4  [explain, need, vaccine, borisjohnson, matthan...        135         14  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11003 entries, 0 to 11002\n",
      "Data columns (total 27 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   user_name         11003 non-null  object\n",
      " 1   user_location     8734 non-null   object\n",
      " 2   user_description  10323 non-null  object\n",
      " 3   user_created      11003 non-null  object\n",
      " 4   user_followers    11003 non-null  int64 \n",
      " 5   user_friends      11003 non-null  int64 \n",
      " 6   user_favourites   11003 non-null  int64 \n",
      " 7   user_verified     11003 non-null  bool  \n",
      " 8   date              11003 non-null  object\n",
      " 9   text              11003 non-null  object\n",
      " 10  hashtags          8426 non-null   object\n",
      " 11  source            11002 non-null  object\n",
      " 12  retweets          11003 non-null  int64 \n",
      " 13  favorites         11003 non-null  int64 \n",
      " 14  is_retweet        11003 non-null  bool  \n",
      " 15  lower             11003 non-null  object\n",
      " 16  remove_ctr        11003 non-null  object\n",
      " 17  review_new        11003 non-null  object\n",
      " 18  tokenized_sent    11003 non-null  object\n",
      " 19  tokenized_word    11003 non-null  object\n",
      " 20  no_punc           11003 non-null  object\n",
      " 21  no_stopwords      11003 non-null  object\n",
      " 22  pos_tags          11003 non-null  object\n",
      " 23  wordnet_pos       11003 non-null  object\n",
      " 24  lemmatized        11003 non-null  object\n",
      " 25  review_len        11003 non-null  int64 \n",
      " 26  word_count        11003 non-null  int64 \n",
      "dtypes: bool(2), int64(7), object(18)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "pfz.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
