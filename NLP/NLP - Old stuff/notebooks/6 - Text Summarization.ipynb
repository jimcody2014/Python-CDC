{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc962580",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Use-caution.--Not-all-examples-will-work!\" data-toc-modified-id=\"Use-caution.--Not-all-examples-will-work!-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Use caution.  Not all examples will work!</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2ee82a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd42919",
   "metadata": {},
   "source": [
    "### Upload radiation.txt to your Google Drive NLP_data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8baf65da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radiation is used in healthcare procedures to help providers find causes of symptoms (diagnostics) and to manage or treat health conditions\n",
      "Although we all are exposed to ionizing radiation every day, any added exposures, including from imaging procedures, slightly increases the risk of developing cancer later in life\n",
      "Usually, the benefits of diagnosing or treating a health problem with an imaging procedure will outweigh these risks\n",
      "Learn about the risks and benefits of common medical imaging procedures\n",
      "Talk to your healthcare provider about the specific risks and benefits of a recommended test for your situation and how to limit your exposure to radiation.}\n",
      "Indexes of top ranked_sentence order are  [(0.34165391554554825, ['Learn', 'about', 'the', 'risks', 'and', 'benefits', 'of', 'common', 'medical', 'imaging', 'procedures']), (0.32275842815351563, ['Usually,', 'the', 'benefits', 'of', 'diagnosing', 'or', 'treating', 'a', 'health', 'problem', 'with', 'an', 'imaging', 'procedure', 'will', 'outweigh', 'these', 'risks']), (0.173951845774836, ['Radiation', 'is', 'used', 'in', 'healthcare', 'procedures', 'to', 'help', 'providers', 'find', 'causes', 'of', 'symptoms', '(diagnostics)', 'and', 'to', 'manage', 'or', 'treat', 'health', 'conditions']), (0.1616358105260999, ['Although', 'we', 'all', 'are', 'exposed', 'to', 'ionizing', 'radiation', 'every', 'day,', 'any', 'added', 'exposures,', 'including', 'from', 'imaging', 'procedures,', 'slightly', 'increases', 'the', 'risk', 'of', 'developing', 'cancer', 'later', 'in', 'life'])]\n",
      "Summarize Text: \n",
      " Learn about the risks and benefits of common medical imaging procedures. Usually, the benefits of diagnosing or treating a health problem with an imaging procedure will outweigh these risks\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    " \n",
    "def read_article(file_name):\n",
    "    file = open(file_name, \"r\")\n",
    "    filedata = file.readlines()\n",
    "    article = filedata[0].split(\". \")\n",
    "    sentences = []\n",
    "\n",
    "    for sentence in article:\n",
    "        print(sentence)\n",
    "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
    "    sentences.pop() \n",
    "    \n",
    "    return sentences\n",
    "\n",
    "def sentence_similarity(sent1, sent2, stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    " \n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    " \n",
    "    all_words = list(set(sent1 + sent2))\n",
    " \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " \n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    " \n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    " \n",
    "    return 1 - cosine_distance(vector1, vector2)\n",
    " \n",
    "def build_similarity_matrix(sentences, stop_words):\n",
    "    # Create an empty similarity matrix\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "def generate_summary(file_name, top_n=5):\n",
    "    stop_words = stopwords.words('english')\n",
    "    summarize_text = []\n",
    "\n",
    "    # Step 1 - Read text anc split it\n",
    "    sentences =  read_article(file_name)\n",
    "\n",
    "    # Step 2 - Generate Similary Martix across sentences\n",
    "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
    "\n",
    "    # Step 3 - Rank sentences in similarity martix\n",
    "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
    "    scores = nx.pagerank(sentence_similarity_graph)\n",
    "\n",
    "    # Step 4 - Sort the rank and pick top sentences\n",
    "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "    print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
    "\n",
    "    for i in range(top_n):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
    "\n",
    "    # Step 5 - Offcourse, output the summarize texr\n",
    "    print(\"Summarize Text: \\n\", \". \".join(summarize_text))\n",
    "\n",
    "# let's begin\n",
    "generate_summary('/Users/jimcody/Documents/2021Python/nlp/data/radiation.txt', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd8f97d",
   "metadata": {},
   "source": [
    "### Use caution.  Not all examples will work!\n",
    "\n",
    "Gensim removed gensim.summarization because "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf764ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim.summarization\n",
    "import gensim\n",
    "from gensim.summarization import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e02c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WILL NOT WORK!!!\n",
    "\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from gensim.summarization import keywords\n",
    "import wikipedia\n",
    "import en_core_web_sm\n",
    " \n",
    "# Get wiki content.\n",
    "wikisearch = wikipedia.page(\"Amitabh Bachchan\")\n",
    "wikicontent = wikisearch.content\n",
    "nlp = en_core_web_sm.load()\n",
    "doc = nlp(wikicontent)\n",
    " \n",
    "# Save the wiki content to a file\n",
    "# (for reference).\n",
    "f = open(\"wikicontent.txt\", \"w\")\n",
    "f.write(wikicontent)\n",
    "f.close()\n",
    " \n",
    "# Summary (0.5% of the original content).\n",
    "summ_per = summarize(wikicontent, ratio = 0.05)\n",
    "print(\"Percent summary\")\n",
    "print(summ_per)\n",
    " \n",
    "# Summary (200 words)\n",
    "summ_words = summarize(wikicontent, word_count = 200)\n",
    "print(\"Word count summary\")\n",
    "print(summ_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49bd4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf837ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
